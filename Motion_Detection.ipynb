{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Motion Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "njNmivlK_hHP"
      },
      "source": [
        "!wget -O video.mp4 https://github.com/heshameraqi/Image_Processing_Computer_Vision_1/raw/main/motion_detection_camera.avi\r\n",
        "\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "cap = cv2.VideoCapture('video.mp4')\r\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # Just to learn it\r\n",
        "frame_height =int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\n",
        "\r\n",
        "ret, frame1 = cap.read()\r\n",
        "ret, frame2 = cap.read()\r\n",
        "i = 1\r\n",
        "while ret:\r\n",
        "    # Get absolute difference image, dilate it, convert it to binary and dilate it for better contours calculation\r\n",
        "    diff = cv2.absdiff(frame1, frame2) # abs(frame1 - frame2)\r\n",
        "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\r\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\r\n",
        "    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\r\n",
        "    dilated = cv2.dilate(thresh, None, iterations=3)\r\n",
        "    # CHAIN_APPROX_NONE stores every pixel, and CHAIN_APPROX_SIMPLE stores only endpoints of the lines that forms the contour\r\n",
        "    # RETR_TREE won't matter because it's how the retrieved contours are ordered (hierarchy)\r\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # Boundaries of connected components\r\n",
        "\r\n",
        "    # Draw Image, difference image ()Contours\r\n",
        "    \"\"\"plt.figure()\r\n",
        "    plt.imshow(frame1)\r\n",
        "    plt.figure()\r\n",
        "    plt.imshow(dilated)\r\n",
        "    plt.figure()\r\n",
        "    cv2.drawContours(frame1, contours, -1, (0, 255, 0), 3)  \r\n",
        "    plt.imshow(frame1)\r\n",
        "    break\"\"\"\r\n",
        "\r\n",
        "    # Mark large contours as moving object\r\n",
        "    for contour in contours:\r\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\r\n",
        "        if cv2.contourArea(contour) < 900: # Safer to increase the expected moving object area to reduce false positives\r\n",
        "            continue\r\n",
        "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\r\n",
        "        cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\r\n",
        "\r\n",
        "    # Save result image\r\n",
        "    image = cv2.resize(frame1, (1280,720))\r\n",
        "    cv2.imwrite(\"Result%04d.jpg\" % i, image)\r\n",
        "    i += 1\r\n",
        "\r\n",
        "    # Read next frame\r\n",
        "    frame1 = frame2\r\n",
        "    ret, frame2 = cap.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKY8ajUBCCUj"
      },
      "source": [
        "**Save & download results video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnpgeG_JB9jy"
      },
      "source": [
        "cap.release()\r\n",
        "# Create the resulted video file, then download it manually if needed and watch the result\r\n",
        "!ffmpeg -framerate 30 -r 30 -i 'Result%04d.jpg' -vcodec mpeg4 -y result.mp4 # Save video\r\n",
        "from google.colab import files\r\n",
        "files.download('result.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}